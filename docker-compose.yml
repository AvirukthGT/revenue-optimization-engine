services:
  # SPARK CLUSTER (The Big Brains)
  # Official Apache Image, but I know it's actually powered by hamsters.

  spark-master:
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    image: my-project/spark-custom:latest
    container_name: spark-master
    hostname: spark-master
    user: root
    environment:
      - SPARK_NO_DAEMONIZE=true
    ports:
      - '9090:8080'
      - '7077:7077'
    volumes:
      - ./spark_jobs:/opt/spark/jobs
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    env_file:
      - .env
    networks:
      - data-network

  spark-worker:
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    image: my-project/spark-custom:latest
    container_name: spark-worker
    user: root
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
    volumes:
      - ./spark_jobs:/opt/spark/jobs
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    env_file:
      - .env
    networks:
      - data-network

  # AIRFLOW (The Traffic Controller)
  # Directing data traffic so I don't have a pile-up on the information superhighway.

  postgres:
    image: postgres:13
    container_name: airflow-postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    networks:
      - data-network

  airflow-init:
    image: apache/airflow:2.7.1
    container_name: airflow-init
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: airflow db init
    networks:
      - data-network

  airflow-webserver:
    image: apache/airflow:2.7.1
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    ports:
      - "8081:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: webserver
    networks:
      - data-network

  airflow-scheduler:
    image: apache/airflow:2.7.1
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    env_file:
      - .env
    networks:
      - data-network

networks:
  data-network:
