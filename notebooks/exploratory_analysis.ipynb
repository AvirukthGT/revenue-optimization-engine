{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420206d6",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bbd37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96441aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from dotenv import load_dotenv  \n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2201300",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('../.env')\n",
    "\n",
    "# Connect to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    warehouse=\"COMPUTE_WH\",\n",
    "    database=\"DYNAMIC_PRICING\",\n",
    "    schema=\"MARTS\"\n",
    ")\n",
    "\n",
    "print('Connection established')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26693470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Query\n",
    "# I want the Full Log (Granular Data) for Machine Learning\n",
    "query = \"\"\"\n",
    "SELECT * FROM DYNAMIC_PRICING.MARTS.MART_FULL_SALES_LOG \n",
    "ORDER BY SALES_DATE DESC\n",
    "\"\"\"\n",
    "\n",
    "# 2. Run Query & Load into Pandas\n",
    "# cursor().execute() runs the query, fetchall() gets the data\n",
    "cur = conn.cursor()\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "\n",
    "# 3. Get Column Names (so the DataFrame isn't just numbers)\n",
    "col_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "# 4. Create the DataFrame\n",
    "df = pd.DataFrame(data, columns=col_names)\n",
    "\n",
    "# 5. Close Connection (Good practice!)\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# 6. Verify\n",
    "print(f\"Success! Loaded {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Data Info ---\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14739b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for Prices and Weather\n",
    "# I filter for relevant columns to avoid noise\n",
    "stats_cols = ['OUR_PRICE', 'COMPETITOR_PRICE', 'TEMPERATURE_C', 'PRECIPITATION_MM', 'PRICE_DIFF']\n",
    "\n",
    "# Describe generates the stats\n",
    "print(df[stats_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique orders per category\n",
    "print(\"--- Sales by Category ---\")\n",
    "print(df['CATEGORY_NAME'].value_counts())\n",
    "\n",
    "# Count weather conditions\n",
    "print(\"\\n--- Weather Conditions ---\")\n",
    "print(df['WEATHER_CONDITION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2616a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the start and end dates\n",
    "print(f\"Data Start Date: {df['SALES_DATE'].min()}\")\n",
    "print(f\"Data End Date:   {df['SALES_DATE'].max()}\")\n",
    "print(f\"Total Days:      {(df['SALES_DATE'].max() - df['SALES_DATE'].min()).days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39338858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the \"Normal\" Range (IQR Rule)\n",
    "Q1 = df['OUR_PRICE'].quantile(0.25)\n",
    "Q3 = df['OUR_PRICE'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# 2. Identify the Outliers\n",
    "outliers = df[(df['OUR_PRICE'] < lower_bound) | (df['OUR_PRICE'] > upper_bound)]\n",
    "\n",
    "print(f\"--- Outlier Report ---\")\n",
    "print(f\"Normal Price Range: ${lower_bound:.2f} to ${upper_bound:.2f}\")\n",
    "print(f\"Number of Outliers detected: {len(outliers)}\")\n",
    "print(f\"Percentage of data that is 'Anomalous': {(len(outliers)/len(df))*100:.2f}%\")\n",
    "\n",
    "# 3. Who are they? (Top 5 Extreme Cases)\n",
    "print(\"\\n--- Top 5 Most Expensive 'Anomalies' ---\")\n",
    "print(outliers.nlargest(5, 'OUR_PRICE')[['SALES_DATE', 'CATEGORY_NAME', 'OUR_PRICE', 'WEATHER_CONDITION']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd69ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split data into two groups: Rainy Days vs Clear Days\n",
    "rainy_sales = df[df['WEATHER_CONDITION'] == 'Rain']['OUR_PRICE']\n",
    "clear_sales = df[df['WEATHER_CONDITION'] == 'Clear']['OUR_PRICE']\n",
    "\n",
    "# 2. Run the T-Test (Independent samples)\n",
    "t_stat, p_val = stats.ttest_ind(rainy_sales, clear_sales, equal_var=False)\n",
    "\n",
    "print(f\"--- Hypothesis Test: Rain vs Clear ---\")\n",
    "print(f\"Rainy Days Mean Revenue: ${rainy_sales.mean():.2f}\")\n",
    "print(f\"Clear Days Mean Revenue: ${clear_sales.mean():.2f}\")\n",
    "print(f\"P-Value: {p_val:.5f}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"RESULT: Statistically Significant! Rain DOES affect sales.\")\n",
    "else:\n",
    "    print(\"RESULT: Not Significant. The difference could be random chance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428741f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I look at 'PRICE_DIFF' (My Price - Competitor)\n",
    "price_diffs = df['PRICE_DIFF'].dropna() # Remove nulls just in case\n",
    "\n",
    "# Calculate 95% Confidence Interval\n",
    "conf_level = 0.95\n",
    "degrees_freedom = len(price_diffs) - 1\n",
    "sample_mean = np.mean(price_diffs)\n",
    "sample_sem = stats.sem(price_diffs) # Standard Error of Mean\n",
    "\n",
    "confidence_interval = stats.t.interval(conf_level, degrees_freedom, sample_mean, sample_sem)\n",
    "\n",
    "print(f\"\\n--- 95% Confidence Interval for Price Difference ---\")\n",
    "print(f\"Sample Mean: ${sample_mean:.2f}\")\n",
    "print(f\"Range: [${confidence_interval[0]:.2f}, ${confidence_interval[1]:.2f}]\")\n",
    "print(\"Interpretation: I am 95% confident the 'True' price difference falls in this range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select numeric columns only\n",
    "corr_cols = ['OUR_PRICE', 'COMPETITOR_PRICE', 'TEMPERATURE_C', 'PRECIPITATION_MM', 'PRICE_DIFF']\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix: What drives what?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f351d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "\n",
    "# 1. Prepare data (Drop nulls just in case)\n",
    "v1 = df['OUR_PRICE'].dropna()\n",
    "v2 = df['COMPETITOR_PRICE'].dropna()\n",
    "\n",
    "# 2. Create Distribution Plot (Histogram + KDE Curve)\n",
    "hist_data = [v1, v2]\n",
    "group_labels = ['My Price', 'Competitor Price']\n",
    "\n",
    "# Create the plot with custom colors\n",
    "fig = ff.create_distplot(hist_data, group_labels, \n",
    "                         bin_size=25, \n",
    "                         show_hist=True, \n",
    "                         show_rug=False,\n",
    "                         colors=['#00D4FF', '#FF5733']) # Blue vs Red\n",
    "\n",
    "fig.update_layout(title_text='Price Distribution: Me vs. Them')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aed16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(df, \n",
    "             x=\"WEATHER_CONDITION\", \n",
    "             y=\"OUR_PRICE\", \n",
    "             color=\"WEATHER_CONDITION\",\n",
    "             points=\"all\", # Show actual data points too\n",
    "             title=\"Revenue Distribution by Weather\",\n",
    "             labels={\"OUR_PRICE\": \"Revenue per Order ($)\"})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.strip(df, \n",
    "               x=\"CATEGORY_NAME\", \n",
    "               y=\"OUR_PRICE\", \n",
    "               color=\"CATEGORY_NAME\", \n",
    "               title=\"Price Consistency by Category\")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67597263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Day of Week (0=Monday, 6=Sunday)\n",
    "df['day_of_week'] = pd.to_datetime(df['SALES_DATE']).dt.day_name()\n",
    "\n",
    "# Sort order for the chart\n",
    "order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "fig = px.box(df, \n",
    "             x=\"day_of_week\", \n",
    "             y=\"OUR_PRICE\", \n",
    "             category_orders={\"day_of_week\": order},\n",
    "             title=\"Sales Distribution by Day of Week\",\n",
    "             color=\"day_of_week\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600afdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# 1. Group by Date to get Total Daily Revenue\n",
    "daily_revenue = df.groupby('SALES_DATE')['OUR_PRICE'].sum().reset_index()\n",
    "\n",
    "# 2. Plot the Trend\n",
    "fig = px.line(daily_revenue, \n",
    "              x='SALES_DATE', \n",
    "              y='OUR_PRICE',\n",
    "              title='Daily Revenue Trend (2016-2018 Data Shifted)',\n",
    "              labels={'OUR_PRICE': 'Total Revenue ($)', 'SALES_DATE': 'Date'})\n",
    "\n",
    "# Add a \"Trendline\" to see the general direction\n",
    "fig.update_traces(line_color='#00D4FF', line_width=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b16f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sum Revenue by Category\n",
    "category_perf = df.groupby('CATEGORY_NAME')['OUR_PRICE'].sum().reset_index()\n",
    "category_perf = category_perf.sort_values('OUR_PRICE', ascending=True) # Sort for better chart\n",
    "\n",
    "# 2. Horizontal Bar Chart\n",
    "fig = px.bar(category_perf, \n",
    "             x='OUR_PRICE', \n",
    "             y='CATEGORY_NAME',\n",
    "             orientation='h', # Horizontal is easier to read\n",
    "             title='Total Revenue by Category',\n",
    "             text_auto='.2s', # Show values like \"10k\"\n",
    "             color='OUR_PRICE',\n",
    "             color_continuous_scale='Bluered')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pivot Table: Rows=Category, Cols=Weather, Values=Average Daily Revenue\n",
    "# I aggregate by MEAN to account for different numbers of rainy vs clear days\n",
    "weather_pivot = df.pivot_table(index='CATEGORY_NAME', \n",
    "                               columns='WEATHER_CONDITION', \n",
    "                               values='OUR_PRICE', \n",
    "                               aggfunc='mean').reset_index()\n",
    "\n",
    "# 2. Calculate the \"Rain Lift\" (How much better/worse is Rain?)\n",
    "# Rain Lift = (Rain Revenue - Clear Revenue) / Clear Revenue\n",
    "weather_pivot['Rain_Lift'] = (weather_pivot['Rain'] - weather_pivot['Clear']) / weather_pivot['Clear']\n",
    "\n",
    "# 3. Plot the Lift\n",
    "fig = px.bar(weather_pivot, \n",
    "             x='Rain_Lift', \n",
    "             y='CATEGORY_NAME',\n",
    "             orientation='h',\n",
    "             title='Impact of Rain on Revenue (Percentage Lift)',\n",
    "             labels={'Rain_Lift': 'Revenue Change in Rain (%)'},\n",
    "             color='Rain_Lift',\n",
    "             color_continuous_scale='RdBu', # Red=Bad, Blue=Good\n",
    "             text_auto='.1%')\n",
    "\n",
    "# Add a line at 0% (No impact)\n",
    "fig.add_vline(x=0, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20106ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select the columns that actually matter\n",
    "cols_to_plot = ['OUR_PRICE', 'COMPETITOR_PRICE', 'TEMPERATURE_C', 'PRECIPITATION_MM']\n",
    "\n",
    "# 2. Create the Pairplot\n",
    "# Hue='WEATHER_CONDITION' lets me see if Rain creates distinct \"clusters\" of data\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.pairplot(df, vars=cols_to_plot, hue='WEATHER_CONDITION', palette='husl', plot_kws={'alpha': 0.5})\n",
    "plt.title(\"Multivariate Interactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot\n",
    "\n",
    "# Resample to Daily Total Revenue (since individual orders are noisy)\n",
    "daily_sales = df.groupby('SALES_DATE')['OUR_PRICE'].sum()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot Lag 1 (Yesterday vs Today)\n",
    "plt.subplot(1, 2, 1)\n",
    "lag_plot(daily_sales, lag=1)\n",
    "plt.title(\"Lag 1 (Yesterday vs Today)\")\n",
    "\n",
    "# Plot Lag 7 (Last Week vs Today)\n",
    "plt.subplot(1, 2, 2)\n",
    "lag_plot(daily_sales, lag=7)\n",
    "plt.title(\"Lag 7 (Same Day Last Week)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abf403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
